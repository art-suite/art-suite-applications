import &StandardImport, &ArtValidation, &Config, {}
  &Filter
  &Session
  &Request

##
  TODO: (July2019)
    Factor out all ArtModels-related stuff
      ArtPipelines should be independent of ArtModels or any other client-side state-management-system.

      Remaining:
        query:    Another declaration passed directly to ArtModels
        aliases:  Another declaration passed directly to ArtModels

class Pipeline extends &RequestHandler
  @abstractClass() # any sub-class that shouldn't auto-register should be an abstract class

  @register: ->
    @singletonClass()
    @getRegistry().register @

  @postCreateConcreteClass: ({hotReloaded}) ->
    @_defineQueryHandlers()
    @_defineClientHandlerMethods()
    @_initFilters()
    @register() unless hotReloaded
    super

  @classGetter
    pipelines: -> @getRegistry().pipelines

  @getAliases: -> @_aliases || {}

  #############################
    ###########################

      Declarative API

    ###########################
    ###########################

  ## @requestTypes extendable property
  @extendableProperty
    requestTypes: {}
  @requestType:   @extendRequestTypes

  ## @fields extendable property
  @extendableProperty
    fields: {}
  @field:         @extendFields

  ## @publicRequestTypes extendable property
    Extend Usage: Pass in one or more names of request-types which are part of the public API.
      @publicRequestType :foo
      @publicRequestTypes :foo :bar :ba

    Get Usage: returns map from public request-types to true
      @getPublicRequestTypes()[:foo] returns true or undefiend
  @extendableProperty
    publicRequestTypes: {}
    {} extend: (publicRequestTypes, values...) ->
      object in w (compactFlatten values).join ' ' into publicRequestTypes with true
  @publicRequestType: @extendPublicRequestTypes

  ## publicHandlers - shorthand for declaring a handler AND marking it as a publicRequestType
  @publicHandlers: publicHandlers = (maps...) ->
    each map in maps
      @handlers map
      @publicRequestTypes Object.keys map
  @publicHandler: publicHandlers

  ## @filter extendable property
    define a single filter OR an array of filters to define.

    NOTE: the order of filter definitions matter:
      last-defined filters FIRST in the before-filter sequence
      last-defined filters LAST in the after-filter sequence

      Example request processing sequence:

        filterDefinedLast.beforeFilter
          filterDefinedSecond.beforeFilter
            filterDefinedFirst.beforeFilter
              handler
            filterDefinedFirst.afterFilter
          filterDefinedSecond.afterFilter
        filterDefinedLast.afterFilter

    IN:
      name: "myFilter"                    # only used for debug purposes
      location: "server"/"client"/"both"  # where the filter will be applied
      before: map:
        requestType: (request) ->
          OUT one of these (or a promise returning one of these):
            request
            - the same request if nothing was filtered
            - a new request with the new, filtered values

            response in the form of:
            - new Request response
            - null        >> request.missing()
            - string      >> request.success data: message: string
            - plainObject >> request.success data: plainObject
            - plainArray  >> request.success data: plainArray
            NOTE, if a response is returned, it shortcircuits the handler and all other
              filters. The response is returned directly to the caller.

      after: map:
        requestType: (response) ->
          OUT: same or new response
            NOTE: all after-filters are applied if the handler generated the first response object
            UNLESS there is an error, in which case the error is returned directly.
  @extendableProperty
    filters: []
    {} extend: (filters, addFilters...) -> filters.concat Filter.preprocessFilters addFilters
  @filter: @extendFilters

  ## @handler extendable property
    add one or more handlers

    IN map:
      requestType: (request) ->
        IN: Request request instance
        OUT:
          Request response instance
        OR
          plain data which will be wrapped up in an Request instance
  @extendableProperty
    handlers: {}
  @handler: @extendHandlers

  ## @query extendable property
    declare a query - used by ArtPipelineModels
    Also used to impliement the action of the query... somehow???

    IN: {}
      queryName: {} #
        query:            (request) -> response
        dataToKeyString:  (data)    -> string
        keyFields:        string[]
        localSort:        (data[]) -> sorted data[]
        localMerge:       (previousQueryData, updatedRecordData, wasDeleted) ->
          IN:
            previousQueryData:  record[] or null
            updatedRecordData:  record[] or null
            wasDeleted:         boolean - true? updatedRecordData is a list of deleted records

    queryName is used as both the ArtModel name AND the ArtPipeline request-type:
      Example:
        # invoke query
        myPipeline.myQueryName key: queryKey

        # subscribe to Model in FluxComponent
        @subscriptions
          myQueryName: queryKey
  @extendableProperty
    queries: {}
    {} extend: (queries, newQueries) -> object options, queryName from newQueries into queries with normalizeQuery queryName, options
  @query: @extendQueries

  ## aliases
    INPUT: zero or more strings or arrays of strings
      - arbitrary nesting of arrays is OK
      - nulls are OK, they are ignored
    OUTPUT: null

    NOTE: @aliases can only be called once

    example:
      class Post extends Pipeline
        @aliases "chapterPost"

    purpose:
      - used by ArtPipelineModels to make model aliases
        (see ArtModel.aliases)
  @aliases: (args...)->
    @_aliases = object v, k from args with-key lowerCamelCase v with true
    @
  @alias: @extendAliases

  ######################
    constructor
  constructor: (_deprecatedOptions) ->
    @_subscribers = {}
    @_querySubscribers = {}
    @_filtersForLocation = {}
    @_groupedFiltersForLocation = {}
    @_filterChainsForLocation = {}
    @_location = getDefaultLocation()

    if _deprecatedOptions
      throw new Error "" DEPRECATED: constructor options. For custom session, use: @registry new PipelineRegistry

  #####################################
    ###################################

      GETTERS - (no important side-effects)

    ###################################
    ###################################
  @classGetter
    :clientApiMethodList
    pipelineName: -> @_pipelineName ? decapitalize @getName()
    recordName:   -> @pipelineName # KeyFieldsMixin expects a recordName method
    pluralPipelineName: ->
      return @_pluralPipelineName if @_pluralPipelineName
      parts = getCodeWords @getPipelineName()
      parts.push pluralize parts.pop()
      @_pluralPipelineName = lowerCamelCase parts

  normalizeFieldsProps = (fieldsProps, fields) -> if fieldsProps then normalizeFieldProps
    switch
    when isString fieldsProps then fieldsProps
    when isPlainObject fieldsProps then fields: fieldsProps
    else throw new Error "expecting Object of fields, or string for singleton. Got: #{formattedInspect fieldsProps}"
    record: {} fields

  @_normalizeRequestResponseProps: (requestType, requestResponseProps, fields) -> if requestResponseProps
    requestResponseProps extract key, keyFields, data, props
    if key == true
      keyFields = @keyFields
      key = object v, k from fields when k in keyFields
      unless objectHasKeys key
        throw new Error "" Error defining requestType '#{@name}.#{requestType}': One or more keyFields (#{formattedInspect keyFields}) are missing from the pipeline's fields definitions: #{Object.keys(@fields).join ', '}
    else if key
      if (keyArray = key) is Array
        each v in keyArray into key = {}
          if v is Object then mergeInto key, v
          else if v is String
            unless key[v] = def = @fields[v]
              throw new Error "" Error defining requestType '#{@name}.#{requestType}': Key's field (#{v}) was not found in the pipeline's fields definitions: #{Object.keys(@fields).join ', '}

      if key is Object
        keyCount = objectKeyCount key
        if keyCount > 1 && keyFields?.length != keyCount
          throw new Error "" Error defining requestType '#{@name}.#{requestType}': Key's definition (#{formattedInspect key}) must have a matching keyFields (#{formattedInspect keyFields}) for serialization purposes

    merge {}
      keyFields
      key:    normalizeFieldsProps key, fields
      data:   normalizeFieldsProps data, fields
      props:  normalizeFieldsProps props, fields

  @classGetter
    normalizedRequestTypes: ->
      @_normalizedRequestTypes ?= object {request, response}, k in @getRequestTypes()
        merge
          request:  if request then   @_normalizeRequestResponseProps k, request, @getFields()
          response: if response then  @_normalizeRequestResponseProps k, response, @getFields()

  @getter
    keyFields:        -> [] :id # use KeyFieldsMixin to add custom key fields
    name:             -> @class.pipelineName
    pipelineName:     -> @class.pipelineName
    recordName:       -> @class.recordName
    normalizedRequestTypes: -> @class.normalizedRequestTypes
    session:          -> @registry.session
    :location
    clientApiMethodList: -> @class.clientApiMethodList

    normalizedFields: -> object v in @fields with normalizeFieldProps v


    # handlerRequestTypesMap: (_into = {}) -> mergeInto _into, @handlers
    # filterRequestTypesMap:  (_into = {}) -> each filter in @filters into _into with mergeInto _into, filter.beforeFilters
    # requestTypesMap:        (_into = {}) -> @getHandlerRequestTypesMap @getFilterRequestTypesMap _into
    # requestTypes:                        -> @_requestTypes ?= Object.keys @requestTypesMap
    aliases:                             -> @_aliases      ?= Object.keys @class.getAliases()

    groupedFilters: -> @_groupedFilters ?= Pipeline.groupFilters @filters
    beforeFilters:  -> @_beforeFilters ?= @groupedFilters.slice().reverse()
    afterFilters:   -> @groupedFilters
    filterChain:    -> @_filterChain ?= compactFlatten([@, @groupedFilters]).reverse()

  getFiltersForLocation: (location) ->
    @_filtersForLocation[location] ?= array filter in @filters when filter.location == location || filter.location == :both

  getGroupedFiltersForLocation: (location) ->
    throw new Error "'both' not supported here" if location == :both
    @_groupedFiltersForLocation[location] ?= Pipeline.groupFilters @getFiltersForLocation location

  getFilterChainForLocation: (location) ->
    validateLocation location
    @_filterChainsForLocation[location] ?=
      compactFlatten []
        @
        if location == :both
          []
            @getGroupedFiltersForLocation :server
            @getGroupedFiltersForLocation :client

        else
          @getGroupedFiltersForLocation location

      .reverse()

  # Inspect Getters
  toString: -> @pipelineName
  getLogName: (requestType) -> "#{requestType}-handler"

  getRequestProcessingReport: (location = @location) ->
    object requestType from log @requestTypes
      compactFlatten []
        array filter in @getBeforeFilters {} requestType, location with inspectedObjectLiteral filter.getName()
        inspectedObjectLiteral if location == :client then "[remote request]" else "[local handler]"
        array filter in @getAfterFilters  {} requestType, location with inspectedObjectLiteral filter.getName()

  @getter
    pipelineReport: (processingLocation)->
      out =
        tableName: @tableName
        fields:
          object fieldProps in @fields
            each k in Object.keys(fieldProps).sort() into out2 = {}
              v = fieldProps[k]
              unless isFunction v
                out2[k] = v

      if processingLocation
        out["#{processingLocation}Processing"]      = @getRequestProcessingReport :client

      else
        out.clientSideRequestProcessing             = @getRequestProcessingReport :client
        out.serverSideRequestProcessing             = @getRequestProcessingReport :server
        out.serverlessDevelopmentRequestProcessing  = @getRequestProcessingReport :both

      out

    inspectedObjects: -> {}
      @name
      publicRequestTypes: Object.keys(@publicRequestTypes).sort()
      requestTypes:       (array @requestTypes).sort()
      subscriberCounts:   object subscribers in @_subscribers with subscribers.length
      querySubscriberCounts:
        object querySubs in @_querySubscribers
          object subscribers in querySubs with subscribers.length

  #####################################
    ###################################

      FILTERS

    ###################################
    ###################################

  # use a stable sort
  @groupFilters: (filters) ->
    priorityLevels = []
    each {priority} in filters
      pushIfNotPresent priorityLevels, priority

    sortedFilters = []
    each priorityLevels in priorityLevels.sort (a, b) -> a - b
      each filter in filters when priorityLevels == filter.priority
        sortedFilters.push filter

    sortedFilters

  getBeforeFilters: (request) -> array filter in @beforeFilters when filter.getBeforeFilter request
  getAfterFilters:  (request) -> array filter in @afterFilters  when filter.getAfterFilter  request

  #####################################
    ###################################

      REQUESTS

    ###################################
    ###################################

  ## cachedGet - convenient alias altenative to request.cachedGet that matches the new subrequest patterns
    IN:
      request: - the request this will be a subrequest-of
      key: <String> (default: request.key)

    EFFECT:
      calls request.cachedGet. Note, cachedGet's cache is stored in request's context
  cachedGet: (request, key) ->
    request.cachedGet @pipelineName, key ? request.key

  createRequest: (type, options) ->
    if getDetailedRequestTracingEnabled()
      stack = (new Error).stack

    Promise
    .then -> options.session || @session.loadedDataPromise
    .tapCatch (error) ->
      log.error Pipeline_createRequest:
        message: "" Error getting session
        info: {} @pipelineName, type, options
        error: error

    .then (sessionData) ->
      new Request merge
        options
        type:     type
        pipeline: @
        session:  sessionData
        creationStack: stack

    .catch (error) ->
      if stack?
        error.stack = cleanStackTrace stack

      error.message += "\n\ninside #{@name}." + formattedInspect createRequest: {type, options}
      throw error

  #####################################
    ###################################

      SUBSCRIPTIONS

    ###################################
    ###################################

  ## subscriber
    IN:
      key: string
      subcriber: (subscriptionEventType, key, data) ->
      queryName: (optional) string matching existing query

    OUT:
      if added then subscriber else undefined

    EFFECT:
      if it didn't already exist
        subscription created
        @subscriberAdded called
  subscribe:   (key, subscriber, queryName) ->
    unless subscriber in subscribersForKey = @_getSubscribers(queryName)[key] ?= []
      push subscribersForKey, subscriber
      @subscriberAdded key, subscriber, queryName
      subscriber

  ## unsubscribe
    IN:
      key: string
      subcriber: (subscriptionEventType, key, data) ->
      queryName: (optional) string matching existing query

    OUT:
      if existed then subscriber else undefined

    EFFECT:
      if it existed
        subscription removed
        @subscriberRemoved called
  unsubscribe: (key, subscriber, queryName) ->
    subscribers = @_getSubscribers queryName
    if subscriber in subscribersForKey = subscribers[key]
      removeFirstMatch subscribersForKey, subscriber
      delete subscribers[key] if subscribersForKey.length == 0
      @subscriberRemoved key, subscriber, queryName
      subscriber

  ## _getSubscribers
    IN:
      queryName: (optional) string matching existing query
  _getSubscribers: (queryName) ->
    if queryName
      unless @queries[queryName]
        throw new Error "Query does not exist. Model: #{@name}. Query: #{queryName}. Existing queries: #{Object.keys(@queries).join ', '}"
      @_querySubscribers[queryName] ?= {}

    else @_subscribers

  ## subscriberAdded - override to get notified
  subscriberAdded: (key, subscriber, queryName) ->

  ## subscriberRemoved - override to get notified
  subscriberRemoved: (key, subscriber, queryName) ->

  dataUpdated: (key, data) -> @_sendDataSubscriptionEvent :update key, data
  dataDeleted: (key, data) -> @_sendDataSubscriptionEvent :delete key, data

  _sendDataSubscriptionEvent: (eventType, key, data) ->
    if isArray dataArray = data
      each data in dataArray
        @_sendDataSubscriptionEventSingle eventType, key, data

    else
      @_sendDataSubscriptionEventSingle eventType, key, data

  _sendDataSubscriptionEventSingle: (eventType, key, data) ->
    each subscriber in @_subscribers[key]
      subscriber eventType, key, data

    # if data isn't proveded, we can't update queries
    data && each querySubscribers, queryName in @_querySubscribers
      queryKey = @queries[queryName].toKeyString data # assumes data contains all fields needed to generate the keyString

      each subscriber in querySubscribers[queryKey]
        subscriber eventType, key, data, queryKey

      ## TODO - Correctly update Query subscribers when record needs to be removed

        We don't currently handle an :update when the changing fields cause the record
        to need to be removed from a local query result.

        Previous Solution Wasn't 100%:

          We fetched the old record's data from the singlton ArtModel. Since
          ArtPipelines are now ArtModel agnostic, that's no longer an option. Even if it was,
          it wasn't foolproof. We may not have a local singleton instance and yet still need
          to update one or more queries.

          NOTE: I didn't even have a half solution for ArtEryPusher updates. I just
          forgot to even consider the possibilty.

        Options:

        1. Maintain a full list of all records we have in use locally,
          regardless if they are in queries or the singleton model
          CON: this breaks the ArtPipelines-doesn't-know-about-ArtModels isolation
          PRO: less DB access; less data over the wire
          (I wish we had WEAK references in JavaScript! Then ArtPipelines could keep
          a WEAK reference to every query result)

        1.5: HRM - we have similar option that could work: Send a :update event to
          all subscribers regardless of the queryKey they are subscribing to.
          CON: more client-side work
          PRO: it should work...
          IMPROVEMENT: if we know what fields were updated, we could skip some update
            messages to queries whos fields didn't change.

        2. OR ArtPipeline :update requests must return the old values for known
          query-fields.
          Ex: response.props.oldData = partialRecord with just the replaced values
          PRO: this is a general solution with wider uses
          PRO: this keeps ArtPipelines agnostic to ArtModels
          PRO: this does solve the server-side ArtEryPusher
          CON: each data-update DB action also needs to read the old values back.
            I think this is freeish in DynamoDB, but other DBs don't do this.

        Conclusion: Option #2 is the only real answer. It's also the only answer that would
        work for ArtEryPusher as well - assuming we have implemented data-over-the-wire for
        Pusher events.

        potential code, assuming we can compute oldQueryKey:
          oldQueryKey = oldData && @queries[queryName].toKeyString oldData
          if oldQueryKey && oldQueryKey != queryKey
            each subscriber in querySubscribers[key]
              subscriber "delete", key, data

  isUpdateRequestType: (actionType) -> /^(create|update)/.test actionType
  isDeleteRequestType: (actionType) -> /^delete/.test actionType

  ######################################
    ####################################

      PRIVATE CLASS METHODS

    ####################################
    ####################################
  ## _defineQueryHandlers
    query handler-functions: (request) -> response or any other value allowed for handlers
  @_defineQueryHandlers: ->
    handlers = @getHandlers()
    each pipelineQuery, k in @getQueries() when !handlers[k]
      handlers = @extendHandlers k, pipelineQuery.options.query

  @_normalizeQuery: normalizeQuery = (queryName, options) ->
    options = query: options if isFunction options
    unless isFunction(options.query) && options.query.length > 0
      throw new Error
        """
          query function must have at least one argument:

          #{formattedInspect {queryName, options}}"

    {dataToKeyString} = options
    toKeyString =
      if dataToKeyString
        (dataOrKey) -> if isPlainObject dataOrKey then dataToKeyString dataOrKey else dataOrKey
      else (key) -> if key? then key.toString() else key

    {} queryName, options, toKeyString

  @_defineClientRequestMethod: (requestType) ->
    @clientApiMethodList.push requestType unless requestType in @clientApiMethodList
    @prototype[requestType] ?= (a, b, c) ~> @_processClientRequest requestType, a, b, c

  @_defineClientHandlerMethods: ->
    @_clientApiMethodList = []
    each __, name in @getHandlers()           with @_defineClientRequestMethod name
    each __, name in @getPublicRequestTypes() with @_defineClientRequestMethod name

  @_initFilters: ->
    # Note, in all things, the pipeline's definitions have priority over the filter's definitions
    each filter in @getFilters() when objectHasKeys filter.fields with @extendFields merge filter.fields, @getFields()

    # requestTypes may depend on FieldTyeps, so run them second
    each filter in @getFilters() when objectHasKeys filter.requestTypes with @extendRequestTypes merge filter.requestTypes, @getRequestTypes()

    each _, name in @getHandlers()
      @extendRequestTypes [name]: {}

    each filter in @getFilters()
      each _, name in filter.before
        @extendRequestTypes [name]: {}

    # validate requestTypes
    @getNormalizedRequestTypes()

  ######################################
    ####################################

      PRIVATE INSTANCE METHODS

    ####################################
    ####################################

  ## handleRequest
    This is really a private method even though this is not called "_handleRequest"
    It overrides the RequestHandler#handleRequest method.
    SEE RequestHandler API
  handleRequest: (request) ->
    if request.isResponse
      throw new Error "HARD DEPRICATED"

    if handler = @handlers[request.type]
      @applyHandler request, handler, :handler
      .then (response) ->
        unless response.isResponse
          request.failure "#{@pipelineName}.#{request.type} request was not handled"

        else
          response

    else
      request.failure "#{@pipelineName}: No handler for request type: #{formattedInspect request.type}"

  _processRequest: (request) ->
    haveHandler = !!@handlers[request.type]
    isPublicRequestType = !!@getPublicRequestTypes()[request.type]

    unless haveHandler || isPublicRequestType
      Promise.then -> request.clientFailure data:
        message: "'#{request.type}' is an invalid request type"
        validRequestTypes: Object.keys @handlers

    else
      filterChain = @getFilterChainForLocation request.location
      request.requireServerOriginOr isPublicRequestType, "to issue non-public requests"
      .then -> filterChain[0].handleRequest request, filterChain, 0
      .tap (response) -> log.error "not response!": response unless response.isResponse

  ## _processClientRequest
    IN:
      LEGAL SIGNATURES:
        type, options?
        type, key?, options?
        type, parentRequest?, options?
        type, parentRequest?, key?, options?

      type:           request type string
      parentRequest:  if present, this becomes a subreqest
      key:            merged with options: merge {key}, options
                      [this is the stringified key]
      options:
        Passed directly to:
          Request constructor
          AND response.toPromise

    OUT: SEE: response.toPromise
  noOptions = {}
  _processClientRequest: (type, a, b, c) ->
    if !a?
      a = b
      b = c

    if a? && a instanceof Request
      parentRequest = a
      a = b
      b = c

    options = if isString a
      merge
        key: a
        b
    else
      a ? noOptions

    if parentRequest
      parentRequest.subrequest @, type,
        if options != noOptions then options
        else props: parentRequest.props

    else
      requestStartTime = currentSecond()

      @createRequest type, options
      .then (request)  -> @_processRequest request
      .then (response) -> @_processResponseSession response, requestStartTime
      .then (response) -> response.toPromise options

  ## _processResponseSession
    mostRecentSessionUpdatedAt ensures we don't update the session out of order
    RULE: the current session reflects the response from the most recently INITIATED request.
    In other words, if a request stalls, takes a long time to update, and comes back with
    a session update AFTER some other session updates from more recently-initiated requests,
    that session-update is ignored.
    keywords: update session

    ALTERNATIVES CONSIDERED
    - could use a server-side timestamp to ensure no out-of-order session updates
      SUBOPTION A: order by time server RECEIVED the request
      SUBOPTION B: order by time server COMPLETED the request
      I decided this made less sense. It's really the order the user initiated
      events that matters. If a user initiates a log-in or log-out request AFTER
      some other slow request, the log-in/log-out should take precidence.
      Extreme example: user logs in, which takes forever, then initiates a log-out,
        if the log-in returns AFTER the log-out, it should be ignored.
  mostRecentSessionUpdatedAt = 0
  _processResponseSession: (response, requestStartTime) ->
    if response extract responseSession
      currentSession = @session.data
      message =
        if requestStartTime > mostRecentSessionUpdatedAt
          mostRecentSessionUpdatedAt = requestStartTime
          @session.data = responseSession
          "" updated

        else
          "" out-of-order update blocked

    response

  #####################################
    ###################################

      Overrides

    ###################################
    ###################################

  ## toKeyString
    IN:
      key: null, undefined, string or plain-object
    OUT:
      if key is null, undefined or string: key is returned untouched
      if key is plain-object: attempt to convert to string

    To Override, add your own custom dataToKeyString method (e.g. use KeyFieldsMixin)
  toKeyString: (key) ->
    switch
    when !key? || isString key then key
    when @dataToKeyString && isPlainObject key then @dataToKeyString key
    else throw new Error "override toKeyString or dataToKeyString for non-string-keys like: #{formattedInspect key}"

  ###################
    propsToKey (primarilly used by ArtPipelineModels)
      NOTE: KeyFieldsMixin overrides this
  @getter
    propsToKey: -> @_propsToKey ?= do ->
      recordType = @pipelineName
      (props, stateField) ->
        propsField = stateField ? recordType
        props[propsField]?.id ? props[propsField + "Id"]

  ## isRecord (override as needed)
    used by Request.withTransformedRecords
    OUT: boolean
  isRecord: (data) -> isPlainObject(data) && present data?.id

  ## getFieldsRequestWillModify (override as needed)
    called by UserOwnedFilter.before.update for correct authorization validation
    overriden by Art.Ery.Aws.DynamoDb to support "add" and "setDefault" for a correct modifications-list

    IN: request
    OUT: object with all fields the request will mutate
      fieldName: fieldValue
  getFieldsRequestWillModify: (request) -> request.data ? {}
