import &StandardImport, &ArtValidation, &Config, &RestClientLib, &RestServerLib, {}
  &Filter
  &DatabaseFilters
  &Session
  &Request
  &PrefetchedRecordsCache

##
  TODO: (July2019)
    Factor out all ArtFlux-related stuff
      ArtEry should be independent of ArtFlux or any other client-side state-management-system.

      Remaining:

        query:
          Another declaration passed directly to ArtFlux

        aliases:
          Another declaration passed directly to ArtFlux

      Perhaps we need a subclass: PipelineWithFluxModel?

    Namespaced-Registry

      I still don't quite know how I want to do this, but I want BOTH ArtFlux (ArtModels?)
      and ArtEry (ArtPipelines?) to have namespaced registries so you can merge as many
      packages as you want based on ArtSuite without name-conflicts in their registries.

preprocessFilters = (filter) ->
  if isPlainArray filter
    array f in filter when f with instantiateFilter f

  else
    instantiateFilter filter

instantiateFilter = (filter) ->
  if isClass filter                 then new filter
  else if isFunction filter         then filter @
  else if filter instanceof Filter  then filter
  else if isPlainObject filter      then new Filter filter
  else throw "" invalid filter: #{inspect filter} #{filter instanceof Filter}

class Pipeline extends &RequestHandler
  @abstractClass() # any sub-class that shouldn't auto-register should be an abstract class

  @register: ->
    @singletonClass()
    @getRegistry().register @

  @postCreateConcreteClass: ({hotReloaded}) ->
    @_defineQueryHandlers()
    @_defineClientHandlerMethods()
    @_initFields()
    @register() unless hotReloaded
    super

  @instantiateFilter: instantiateFilter

  @getAliases: -> @_aliases || {}

  @addDatabaseFilters: (options) ->
    @filter DatabaseFilters.createDatabaseFilters options, @

  @addDatabaseFiltersV2: (options) ->
    @filter DatabaseFilters.createDatabaseFilters
      merge
        linkFilterVersion: 2
        options

      @

  #############################
    ###########################

      Declarative API

    ###########################
    ###########################
  @extendableProperty
    queries: {}
    filters: []
    handlers: {}
    clientApiMethodList: []
    fields: {}
    publicRequestTypes: {}

  @publicRequestTypes: (values...) ->
    publicRequestTypes = {}
    each v in compactFlatten values
      each k in w v
        publicRequestTypes[k] = true

    @extendPublicRequestTypes publicRequestTypes

  # delcare handlers and publicRequestTypes as one
  @publicHandlers: (maps...) ->
    each map in maps
      @handlers map
      @publicRequestTypes Object.keys map

  ## filter
    define a single filter OR an array of filters to define.

    NOTE: the order of filter definitions matter:
      last-defined filters FIRST in the before-filter sequence
      last-defined filters LAST in the after-filter sequence

      Example request processing sequence:

        filterDefinedLast.beforeFilter
          filterDefinedSecond.beforeFilter
            filterDefinedFirst.beforeFilter
              handler
            filterDefinedFirst.afterFilter
          filterDefinedSecond.afterFilter
        filterDefinedLast.afterFilter

    IN:
      name: "myFilter"                    # only used for debug purposes
      location: "server"/"client"/"both"  # where the filter will be applied
      before: map:
        requestType: (request) ->
          OUT one of these (or a promise returning one of these):
            request
            - the same request if nothing was filtered
            - a new request with the new, filtered values

            response in the form of:
            - new Request response
            - null        >> request.missing()
            - string      >> request.success data: message: string
            - plainObject >> request.success data: plainObject
            - plainArray  >> request.success data: plainArray
            NOTE, if a response is returned, it shortcircuits the handler and all other
              filters. The response is returned directly to the caller.

      after: map:
        requestType: (response) ->
          OUT: same or new response
            NOTE: all after-filters are applied if the handler generated the first response object
            UNLESS there is an error, in which case the error is returned directly.
  @filter:        (filter)         -> @extendFilters preprocessFilters filter

  ## handler
    add one or more handlers

    IN map:
      requestType: (request) ->
        IN: Request request instance
        OUT:
          Request response instance
        OR
          plain data which will be wrapped up in an Request instance

    @handler and @handlers are aliases.
  @handler:  @extendHandlers
  @handlers: @extendHandlers

  ## query
    declare a query - used by ArtEryFlux

    IN: map:
      queryName: map:
        class properties for anonymous subclass of ArtEryQueryFluxModel

    queryName is used as both the ArtFlux model-name AND the ArtEry request-type:
      Example:
        # invoke query
        myPipeline.myQueryName key: queryKey

        # subscribe to Model in FluxComponent
        @subscriptions
          myQueryName: queryKey
  @query: (map) ->
    @extendQueries object options, queryName from map with @_normalizeQuery queryName, options

  ## aliases
    INPUT: zero or more strings or arrays of strings
      - arbitrary nesting of arrays is OK
      - nulls are OK, they are ignored
    OUTPUT: null

    NOTE: @aliases can only be called once

    example:
      class Post extends Pipeline
        @aliases "chapterPost"

    purpose:
      - used by ArtEryFluxComponent to make model aliases
        (see FluxModel.aliases)
  @aliases: (args...)->
    @_aliases = object v, k from args with-key lowerCamelCase v with true
    @

  ######################
    constructor
  constructor: (_deprecatedOptions) ->
    @_subscribers = {}
    @_querySubscribers = {}
    if _deprecatedOptions
      throw new Error "" DEPRECATED: constructor options. For custom session, use: @registry new PipelineRegistry

  #####################################
    ###################################

      GETTERS - (no important side-effects)

    ###################################
    ###################################
  @classGetter
    pipelineName: -> @_pipelineName ? decapitalize @getName()
    pluralPipelineName: ->
      return @_pluralPipelineName if @_pluralPipelineName
      parts = getCodeWords @getPipelineName()
      parts.push pluralize parts.pop()
      @_pluralPipelineName = lowerCamelCase parts

  @getter
    name:             -> @class.pipelineName
    pipelineName:     -> @class.pipelineName
    session:          -> @registry.session

    normalizedFields: ->
      nf = {}
      each v, k in @fields
        nf[k] = normalizeFieldProps v

      nf

    handlerRequestTypesMap: (_into = {}) -> mergeInto _into, @handlers
    filterRequestTypesMap:  (_into = {}) -> each filter in @filters into _into with mergeInto _into, filter.beforeFilters
    requestTypesMap:        (_into = {}) -> @getHandlerRequestTypesMap @getFilterRequestTypesMap _into
    requestTypes:                        -> @_requestTypes ?= Object.keys @requestTypesMap
    aliases:                             -> @_aliases      ?= Object.keys @class.getAliases()

    groupedFilters: -> @_groupedFilters ?= Pipeline.groupFilters @filters
    beforeFilters:  -> @_beforeFilters ?= @groupedFilters.slice().reverse()
    afterFilters:   -> @groupedFilters
    filterChain:    -> @_filterChain ||= compactFlatten([@, @groupedFilters]).reverse()

  # Inspect Getters
  toString: -> @pipelineName
  getLogName: (requestType) -> "#{requestType}-handler"

  getRequestProcessingReport: (location = @location) ->
    object requestType from @requestTypes
      compactFlatten []
        array filter in @getBeforeFilters {} requestType, location with inspectedObjectLiteral filter.getName()
        inspectedObjectLiteral if location == :client then "[remote request]" else "[local handler]"
        array filter in @getAfterFilters  {} requestType, location with inspectedObjectLiteral filter.getName()

  @getter
    pipelineReport: (processingLocation)->
      out =
        tableName: @tableName
        fields:
          object fieldProps in @fields
            each k in Object.keys(fieldProps).sort() into out2 = {}
              v = fieldProps[k]
              unless isFunction v
                out2[k] = v

      if processingLocation
        out["#{processingLocation}Processing"]      = @getRequestProcessingReport :client

      else
        out.clientSideRequestProcessing             = @getRequestProcessingReport :client
        out.serverSideRequestProcessing             = @getRequestProcessingReport :server
        out.serverlessDevelopmentRequestProcessing  = @getRequestProcessingReport :both

      out

    inspectedObjects: -> {}
      @name
      publicRequestTypes: Object.keys(@publicRequestTypes).sort()
      requestTypes: (array @requestTypes).sort()
      subscriberCounts: object subscribers in @_subscribers with subscribers.length
      querySubscriberCounts:
        object querySubs in @_querySubscribers
          object subscribers in querySubs with subscribers.length

  #####################################
    ###################################

      FILTERS

    ###################################
    ###################################

  # use a stable sort
  @groupFilters: (filters) ->
    priorityLevels = []
    each {priority} in filters
      pushIfNotPresent priorityLevels, priority

    sortedFilters = []
    each priorityLevels in priorityLevels.sort (a, b) -> a - b
      each filter in filters when priorityLevels == filter.priority
        sortedFilters.push filter

    sortedFilters

  getBeforeFilters: (request) -> array filter in @beforeFilters when filter.getBeforeFilter request
  getAfterFilters:  (request) -> array filter in @afterFilters  when filter.getAfterFilter  request

  #####################################
    ###################################

      REQUESTS

    ###################################
    ###################################

  ## cachedGet - convenient alias altenative to request.cachedGet that matches the new subrequest patterns
    IN:
      request: - the request this will be a subrequest-of
      key: <String> (default: request.key)

    EFFECT:
      calls request.cachedGet. Note, cachedGet's cache is stored in request's context
  cachedGet: (request, key) ->
    request.cachedGet @pipelineName, key ? request.key

  createRequest: (type, options) ->
    log.warn "DEPRICATED - options must be an object now" unless isPlainObject options
    options = key: options if isString options

    if getDetailedRequestTracingEnabled()
      stack = (new Error).stack

    Promise
    .then => options.session || @session.loadedDataPromise
    .tapCatch (error) =>
      log.error Pipeline_createRequest:
        message: "Error getting session"
        info: {@pipelineName, type, options}
        error: error

    .then (sessionData) =>
      new Request merge
        options
        type:     type
        pipeline: @
        session:  sessionData
        creationStack: stack

    .catch (error) =>
      if stack?
        error.stack = cleanStackTrace stack

      error.message += "\n\ninside #{@name}." + formattedInspect createRequest: {type, options}
      throw error

  #####################################
    ###################################

      SUBSCRIPTIONS

    ###################################
    ###################################

  ## subscriber
    IN:
      key: string
      subcriber: (subscriptionEventType, key, data) ->
      queryName: (optional) string matching existing query

    OUT:
      if added then subscriber else undefined

    EFFECT:
      if it didn't already exist
        subscription created
        @subscriberAdded called
  subscribe:   (key, subscriber, queryName) ->
    unless subscriber in subscribersForKey = @_getSubscribers(queryName)[key] ?= []
      push subscribersForKey, subscriber
      @subscriberAdded key, subscriber, queryName
      subscriber

  ## unsubscribe
    IN:
      key: string
      subcriber: (subscriptionEventType, key, data) ->
      queryName: (optional) string matching existing query

    OUT:
      if existed then subscriber else undefined

    EFFECT:
      if it existed
        subscription removed
        @subscriberRemoved called
  unsubscribe: (key, subscriber, queryName) ->
    subscribers = @_getSubscribers queryName
    if subscribersForKey = subscribers[key]
      removeFirstMatch subscribersForKey, subscriber
      if subscribersForKey.length == 0
        delete subscribers[key]
        @subscriberRemoved key, subscriber, queryName
        subscriber


  ## _getSubscribers
    IN:
      queryName: (optional) string matching existing query
  _getSubscribers: (queryName) ->
    if queryName
      unless @queries[queryName]
        throw new Error "Query does not exist. Model: #{@name}. Query: #{queryName}. Existing queries: #{Object.keys(@queries).join ', '}"
      @_querySubscribers[queryName] ?= {}

    else @_subscribers

  ## subscriberAdded - override to get notified
  subscriberAdded: (key, subscriber, queryName) ->

  ## subscriberRemoved - override to get notified
  subscriberRemoved: (key, subscriber, queryName) ->

  dataUpdated: (key, data) -> @_sendDataSubscriptionEvent :update key, data
  dataDeleted: (key, data) -> @_sendDataSubscriptionEvent :delete key, data

  _sendDataSubscriptionEvent: (eventType, key, data) ->
    if isArray dataArray = data
      each data in dataArray
        @_sendDataSubscriptionEventSingle eventType, key, data

    else
      @_sendDataSubscriptionEventSingle eventType, key, data

  _sendDataSubscriptionEventSingle: (eventType, key, data) ->
    each subscriber in @_subscribers[key]
      subscriber eventType, key, data

    # if data isn't proveded, we can't update queries
    data && each querySubscribers, queryName in @_querySubscribers
      queryKey = @queries[queryName].toKeyString data # assumes data contains all fields needed to generate the keyString

      each subscriber in querySubscribers[queryKey]
        subscriber eventType, key, data, queryKey

      ## TODO - Correctly update Query subscribers when record needs to be removed

        We don't currently handle an :update when the changing fields cause the record
        to need to be removed from a local query result.

        Previous Solution Wasn't 100%:

          We fetched the old record's data from the singlton ArtModel. Since
          ArtPipelines are now ArtModel agnostic, that's no longer an option. Even if it was,
          it wasn't foolproof. We may not have a local singleton instance and yet still need
          to update one or more queries.

          NOTE: I didn't even have a half solution for ArtEryPusher updates. I just
          forgot to even consider the possibilty.

        Options:

        1. Maintain a full list of all records we have in use locally,
          regardless if they are in queries or the singleton model
          CON: this breaks the ArtPipelines-doesn't-know-about-ArtModels isolation
          PRO: less DB access; less data over the wire
          (I wish we had WEAK references in JavaScript! Then ArtPipelines could keep
          a WEAK reference to every query result)

        1.5: HRM - we have similar option that could work: Send a :update event to
          all subscribers regardless of the queryKey they are subscribing to.
          CON: more client-side work
          PRO: it should work...
          IMPROVEMENT: if we know what fields were updated, we could skip some update
            messages to queries whos fields didn't change.

        2. OR ArtPipeline :update requests must return the old values for known
          query-fields.
          Ex: response.props.oldData = partialRecord with just the replaced values
          PRO: this is a general solution with wider uses
          PRO: this keeps ArtPipelines agnostic to ArtModels
          PRO: this does solve the server-side ArtEryPusher
          CON: each data-update DB action also needs to read the old values back.
            I think this is freeish in DynamoDB, but other DBs don't do this.

        Conclusion: Option #2 is the only real answer. It's also the only answer that would
        work for ArtEryPusher as well - assuming we have implemented data-over-the-wire for
        Pusher events.

        potential code, assuming we can compute oldQueryKey:
          oldQueryKey = oldData && @queries[queryName].toKeyString oldData
          if oldQueryKey && oldQueryKey != queryKey
            each subscriber in querySubscribers[key]
              subscriber "delete", key, data

  isUpdateRequestType: (actionType) -> /^(create|update)/.test actionType
  isDeleteRequestType: (actionType) -> /^delete/.test actionType

  ######################################
    ####################################

      PRIVATE CLASS METHODS

    ####################################
    ####################################
  ## _defineQueryHandlers
    query handler-functions: (request) -> response or any other value allowed for handlers
  @_defineQueryHandlers: ->
    handlers = @getHandlers()
    each pipelineQuery, k in @getQueries() when !handlers[k]
      handlers = @extendHandlers k, pipelineQuery.options.query

  @_normalizeQuery: (queryName, options) ->
    options = query: options if isFunction options
    unless isFunction(options.query) && options.query.length > 0
      throw new Error
        """
          query function must have at least one argument:

          #{formattedInspect {queryName, options}}"

    {dataToKeyString} = options
    toKeyString =
      if dataToKeyString
        (dataOrKey) -> if isPlainObject dataOrKey then dataToKeyString dataOrKey else dataOrKey
      else (key) -> if key? then key.toString() else key

    {} queryName, options, toKeyString

  @_defineClientRequestMethod: (requestType) ->
    @extendClientApiMethodList requestType unless requestType in @getClientApiMethodList()
    @prototype[requestType] ?= (a, b, c) ~> @_processClientRequest requestType, a, b, c

  @_defineClientHandlerMethods: ->
    each __, name in @getHandlers()           with @_defineClientRequestMethod name
    each __, name in @getPublicRequestTypes() with @_defineClientRequestMethod name

  @_initFields: ->
    each filter in @getFilters() with @extendFields filter.fields

  ######################################
    ####################################

      PRIVATE INSTANCE METHODS

    ####################################
    ####################################
  _normalizeRequest: (request) ->
    if isPlainObject request
      new Request merge request, pipeline: @

    else
      request

  ## handleRequest
    This is really a private method even though this is not called "_handleRequest"
    It overrides the RequestHandler#handleRequest method.
    SEE RequestHandler API
  handleRequest: (request) ->
    if request.isResponse
      throw new Error "HARD DEPRICATED"

    if @location == :client && @remoteServer
      sendRemoteRequest request

    else if handler = @handlers[request.type]
      @applyHandler request, handler, :handler
      .then (response) =>
        unless response.isResponse
          request.failure "#{@pipelineName}.#{request.type} request was not handled"

        else
          response

    else
      request.failure "#{@pipelineName}: No handler for request type: #{formattedInspect request.type}"

  _processRequest: (request) ->
    haveHandler = !!@handlers[request.type]
    isPublicRequestType = !!@getPublicRequestTypes()[request.type]

    unless haveHandler || isPublicRequestType
      Promise.then => request.clientFailure data:
        message: "'#{request.type}' is an invalid request type"
        validRequestTypes: Object.keys @handlers

    else
      request.requireServerOriginOr isPublicRequestType, "to issue non-public requests"
      .then -> @filterChain[0].handleRequest request, @filterChain, 0
      .tap (response) -> log.error "not response!": response unless response.isResponse

  ## _processClientRequest
    IN:
      LEGAL SIGNATURES:
        type, options?
        type, key?, options?
        type, parentRequest?, options?
        type, parentRequest?, key?, options?

      type:           request type string
      parentRequest:  if present, this becomes a subreqest
      key:            merged with options: merge {key}, options
                      [this is the stringified key]
      options:
        Passed directly to:
          Request constructor
          AND response.toPromise

    OUT: SEE: response.toPromise
  noOptions = {}
  _processClientRequest: (type, a, b, c) ->
    if !a?
      a = b
      b = c

    if a? && a instanceof Request
      parentRequest = a
      a = b
      b = c

    options = if isString a
      merge
        key: a
        b
    else
      a ? noOptions

    if parentRequest
      parentRequest.subrequest @, type,
        if options != noOptions then options
        else props: parentRequest.props

    else
      requestStartTime = currentSecond()

      @createRequest type, options
      .then (request)  -> @_processRequest request
      .then (response) -> @_processResponseSession response, requestStartTime
      .then (response) -> response.toPromise options

  ## _processResponseSession
    mostRecentSessionUpdatedAt ensures we don't update the session out of order
    RULE: the current session reflects the response from the most recently INITIATED request.
    In other words, if a request stalls, takes a long time to update, and comes back with
    a session update AFTER some other session updates from more recently-initiated requests,
    that session-update is ignored.
    keywords: update session

    ALTERNATIVES CONSIDERED
    - could use a server-side timestamp to ensure no out-of-order session updates
      SUBOPTION A: order by time server RECEIVED the request
      SUBOPTION B: order by time server COMPLETED the request
      I decided this made less sense. It's really the order the user initiated
      events that matters. If a user initiates a log-in or log-out request AFTER
      some other slow request, the log-in/log-out should take precidence.
      Extreme example: user logs in, which takes forever, then initiates a log-out,
        if the log-in returns AFTER the log-out, it should be ignored.
  mostRecentSessionUpdatedAt = 0
  _processResponseSession: (response, requestStartTime) ->
    if response extract responseSession
      currentSession = @session.data
      message =
        if requestStartTime > mostRecentSessionUpdatedAt
          mostRecentSessionUpdatedAt = requestStartTime
          @session.data = responseSession
          "" updated

        else
          "" out-of-order update blocked

    response

  #####################################
    ###################################

      Overrides

    ###################################
    ###################################

  ## toKeyString
    IN:
      key: null, undefined, string or plain-object
    OUT:
      if key is null, undefined or string: key is returned untouched
      if key is plain-object: attempt to convert to string

    To Override, add your own custom dataToKeyString method (e.g. use KeyFieldsMixin)
  toKeyString: (key) ->
    switch
    when !key? || isString key then key
    when @dataToKeyString && isPlainObject key then @dataToKeyString key
    else throw new Error "override toKeyString or dataToKeyString for non-string-keys like: #{formattedInspect key}"

  ###################
    propsToKey (primarilly used by ArtEryFluxModel)
      NOTE: KeyFieldsMixin overrides this
  @getter
    propsToKey: -> @_propsToKey ?= do =>
      recordType = @pipelineName
      (props, stateField) ->
        propsField = stateField ? recordType
        props[propsField]?.id ? props[propsField + "Id"]

  ## isRecord (override as needed)
    used by Request.withTransformedRecords
    OUT: boolean
  isRecord: (data) -> isPlainObject(data) && present data?.id

  ## getFieldsRequestWillModify (override as needed)
    called by UserOwnedFilter.before.update for correct authorization validation
    overriden by Art.Ery.Aws.DynamoDb to support "add" and "setDefault" for a correct modifications-list

    IN: request
    OUT: object with all fields the request will mutate
      fieldName: fieldValue
  getFieldsRequestWillModify: (request) -> request.data ? {}

  #####################################
    ###################################

      REST Transport Extensions

    ###################################
    ###################################

    Also SEE: handleRequest

  @getter
    isRemoteClient:   -> !!@remoteServer
    apiRoot:          -> @class._apiRoot ? config._apiRoot
    remoteServer:     -> @class._remoteServer ? config.remoteServer
    restPath:         -> @_restPath ?= getPipelineRestPath @
    restPathRegex:    -> @_restPathRegex ?= getPipelineRestPathRegex @

    location: ->
      if @remoteServer && config.location != :server
        :client

      else config.location

  @remoteServer:    (@_remoteServer)    -> # override default (see config.remoteServer)
  @apiRoot:         (@_apiRoot)         -> # override default (see config.apiRoot)

  @getter
    apiReport: (options = {}) -> apiReport @, options

  #####################################
    ###################################

      Database / RecordPipeline Extensions

    ###################################
    ###################################

    Big question, do these count as RecordPipeline extensions?

      @queries
      @fields

  @tableNamePrefix: (@_tableNamePrefix) -> # override default (see config.tableNamePrefix)
  getPrefixedTableName: (tableName) -> "#{@tableNamePrefix}#{tableName}"

  @getter
    tableNamePrefix:        -> @class._tableNamePrefix ? config.tableNamePrefix
    tableName:              -> @getPrefixedTableName @name
    prefetchedRecordsCache: -> @registry.prefetchedRecordsCache

  getPrefetchedRecord: (key) -> @prefetchedRecordsCache.get @pipelineName, key
